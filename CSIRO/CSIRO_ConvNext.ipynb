{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9146718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in LOCAL environment\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/8: 100%|██████████| 19/19 [00:26<00:00,  1.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train=1275.5123  Val=1256.1846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/8: 100%|██████████| 19/19 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train=1192.8734  Val=995.8061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/8: 100%|██████████| 19/19 [00:06<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train=873.0203  Val=573.0002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/8: 100%|██████████| 19/19 [00:06<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train=525.4929  Val=440.3355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/8: 100%|██████████| 19/19 [00:06<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train=433.8575  Val=316.3148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/8: 100%|██████████| 19/19 [00:06<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train=359.2002  Val=256.5038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/8: 100%|██████████| 19/19 [00:06<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train=313.5235  Val=235.2583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/8: 100%|██████████| 19/19 [00:06<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train=299.6916  Val=256.0292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting TEST: 100%|██████████| 1/1 [00:01<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved submission: /home/rameyjm7/workspace/datasets/CSIRO/submission.csv\n",
      "                    sample_id     target\n",
      "0  ID1001187975__Dry_Clover_g   5.726462\n",
      "1    ID1001187975__Dry_Dead_g  10.555432\n",
      "2   ID1001187975__Dry_Green_g  27.412813\n",
      "3   ID1001187975__Dry_Total_g  42.583504\n",
      "4         ID1001187975__GDM_g  31.700449\n",
      "Shape: (5, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ================================================================\n",
    "# ConvNeXt-L Multi-Task Biomass Regression — FULL WORKING CELL\n",
    "# ================================================================\n",
    "import os, numpy as np, pandas as pd, warnings\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# ENVIRONMENT PATHS (LOCAL OR KAGGLE)\n",
    "# -------------------------------------------------------------\n",
    "if os.path.exists(\"/kaggle/input\"):\n",
    "    print(\"Running in KAGGLE environment\")\n",
    "    BASE = \"/kaggle/input/csiro-biomass\"\n",
    "    TRAIN_CSV = f\"{BASE}/train.csv\"\n",
    "    TEST_CSV  = f\"{BASE}/test.csv\"\n",
    "    TRAIN_IMG = f\"{BASE}/train\"\n",
    "    TEST_IMG  = f\"{BASE}/test\"\n",
    "    SAVE_PATH = \"/kaggle/working/submission.csv\"\n",
    "else:\n",
    "    print(\"Running in LOCAL environment\")\n",
    "    BASE = \"/home/rameyjm7/workspace/datasets/CSIRO\"\n",
    "    TRAIN_CSV = f\"{BASE}/train.csv\"\n",
    "    TEST_CSV  = f\"{BASE}/test.csv\"\n",
    "    TRAIN_IMG = f\"{BASE}/train\"\n",
    "    TEST_IMG  = f\"{BASE}/test\"\n",
    "    SAVE_PATH = f\"{BASE}/submission.csv\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# LOAD DATA\n",
    "# -------------------------------------------------------------\n",
    "df = pd.read_csv(TRAIN_CSV)\n",
    "df[\"sample_id_base\"] = df[\"sample_id\"].apply(lambda x: x.split(\"__\")[0])\n",
    "\n",
    "targets = [\"Dry_Green_g\",\"Dry_Dead_g\",\"Dry_Clover_g\",\"GDM_g\",\"Dry_Total_g\"]\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# MULTI-TASK DATASET\n",
    "# -------------------------------------------------------------\n",
    "class BiomassDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        sid = row[\"sample_id_base\"]\n",
    "        img = Image.open(os.path.join(self.img_dir, f\"{sid}.jpg\")).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        y = row[targets].values.astype(np.float32)\n",
    "        return img, torch.tensor(y)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# IMAGE TRANSFORMS FOR CONVNEXT-L\n",
    "# -------------------------------------------------------------\n",
    "transform = T.Compose([\n",
    "    T.Resize((384, 384)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# TRAIN/VAL SPLIT\n",
    "# -------------------------------------------------------------\n",
    "pivot = df.pivot(index=\"sample_id_base\", columns=\"target_name\", values=\"target\").reset_index()\n",
    "X = pivot\n",
    "y = pivot[targets]\n",
    "\n",
    "train_df, val_df = train_test_split(pivot, test_size=0.15, random_state=42)\n",
    "\n",
    "train_ds = BiomassDataset(train_df, TRAIN_IMG, transform)\n",
    "val_ds   = BiomassDataset(val_df, TRAIN_IMG, transform)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_ds, batch_size=16, shuffle=False, num_workers=4)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# CONVNEXT-L MULTI-TASK MODEL (FIXED VERSION)\n",
    "# -------------------------------------------------------------\n",
    "class ConvNeXtL_MTL(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = models.convnext_large(\n",
    "            weights=models.ConvNeXt_Large_Weights.IMAGENET1K_V1\n",
    "        )\n",
    "\n",
    "        # Remove classifier\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        # ConvNeXt output: (B, 1536, H/32, W/32)\n",
    "        # FIX: Add global average pooling\n",
    "        self.pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(1536, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 5)     # 5 regression outputs\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone.features(x)\n",
    "        x = self.pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.head(x)\n",
    "\n",
    "model = ConvNeXtL_MTL().to(device)\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# TRAINING SETUP\n",
    "# -------------------------------------------------------------\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=1e-4)\n",
    "criterion = nn.MSELoss()\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(device==\"cuda\"))\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# TRAINING LOOP\n",
    "# -------------------------------------------------------------\n",
    "EPOCHS = 8\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for imgs, ys in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\"):\n",
    "        imgs, ys = imgs.to(device), ys.to(device)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with torch.cuda.amp.autocast(enabled=(device==\"cuda\")):\n",
    "            preds = model(imgs)\n",
    "            loss = criterion(preds, ys)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item() * imgs.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # ---------------------- VALIDATION ----------------------\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, ys in val_loader:\n",
    "            imgs, ys = imgs.to(device), ys.to(device)\n",
    "            preds = model(imgs)\n",
    "            val_loss += criterion(preds, ys).item() * imgs.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch}: Train={train_loss:.4f}  Val={val_loss:.4f}\")\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# FULL TEST SET PREDICTION\n",
    "# -------------------------------------------------------------\n",
    "test_df = pd.read_csv(TEST_CSV)\n",
    "test_df[\"sample_id_base\"] = test_df[\"sample_id\"].apply(lambda x: x.split(\"__\")[0])\n",
    "unique_ids = test_df[\"sample_id_base\"].unique()\n",
    "\n",
    "test_preds = {}\n",
    "\n",
    "for sid in tqdm(unique_ids, desc=\"Predicting TEST\"):\n",
    "    img_path = os.path.join(TEST_IMG, f\"{sid}.jpg\")\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x).cpu().numpy()[0]\n",
    "\n",
    "    test_preds[sid] = pred\n",
    "\n",
    "# -------------------------------------------------------------\n",
    "# BUILD FINAL SUBMISSION\n",
    "# -------------------------------------------------------------\n",
    "rows = []\n",
    "for _, row in test_df.iterrows():\n",
    "    sid = row[\"sample_id_base\"]\n",
    "    tname = row[\"target_name\"]\n",
    "    idx = targets.index(tname)\n",
    "    rows.append({\n",
    "        \"sample_id\": row[\"sample_id\"],\n",
    "        \"target\": float(test_preds[sid][idx])\n",
    "    })\n",
    "\n",
    "submission = pd.DataFrame(rows)\n",
    "submission.to_csv(SAVE_PATH, index=False)\n",
    "\n",
    "print(\"\\nSaved submission:\", SAVE_PATH)\n",
    "print(submission.head())\n",
    "print(\"Shape:\", submission.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
