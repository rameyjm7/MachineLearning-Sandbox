{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "064fdbfc-94b0-4917-91db-c6d620feeac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-23 21:16:17.937618: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-23 21:16:17.949653: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745457377.962869  865759 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745457377.966772  865759 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-23 21:16:17.981115: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High SNR samples: 44000\n",
      "Low SNR samples: 176000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the dataset\n",
    "with open(\"RML2016.10a_dict.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "# Prepare data and return SNR values along with samples and labels\n",
    "def prepare_data_with_snr(data):\n",
    "    X, y, snr_values = [], [], []\n",
    "    for (mod_type, snr), signals in data.items():\n",
    "        for signal in signals:\n",
    "            iq_signal = np.vstack([signal[0], signal[1]]).T\n",
    "            # Create a column with the SNR value (same value repeated for each time step)\n",
    "            snr_signal = np.full((128, 1), snr)\n",
    "            combined_signal = np.hstack([iq_signal, snr_signal])\n",
    "            X.append(combined_signal)\n",
    "            y.append(mod_type)\n",
    "            snr_values.append(snr)\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    snr_values = np.array(snr_values)\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    return X, y_encoded, snr_values, label_encoder\n",
    "\n",
    "# Get full dataset with SNR values\n",
    "X_all, y_all, snr_all, label_encoder = prepare_data_with_snr(data)\n",
    "\n",
    "# Split dataset into high SNR (>= -6dB) and low SNR (< -6dB)\n",
    "mask_high = snr_all >= 12\n",
    "mask_low = snr_all < 12\n",
    "\n",
    "X_high = X_all[mask_high]\n",
    "y_high = y_all[mask_high]\n",
    "X_low = X_all[mask_low]\n",
    "y_low = y_all[mask_low]\n",
    "\n",
    "print(\"High SNR samples:\", X_high.shape[0])\n",
    "print(\"Low SNR samples:\", X_low.shape[0])\n",
    "\n",
    "# Split the high SNR dataset into training and testing sets\n",
    "X_train_high, X_test_high, y_train_high, y_test_high = train_test_split(\n",
    "    X_high, y_high, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Ensure proper shape (each sample is already of shape (128, 3))\n",
    "X_train_high = X_train_high.reshape(-1, X_train_high.shape[1], X_train_high.shape[2])\n",
    "X_test_high = X_test_high.reshape(-1, X_test_high.shape[1], X_test_high.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ae6a251-a2d4-45bc-9ba6-52e8e42e834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model from lstm_rnn_2024.keras\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1745457424.249501  865759 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1041 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 0000:ca:00.0, compute capability: 8.0\n",
      "I0000 00:00:1745457425.995286  866060 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m550/550\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9265 - loss: 0.1594 - val_accuracy: 0.9153 - val_loss: 0.1699\n",
      "Model saved to lstm_rnn_2024.keras\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the model\n",
    "def build_model(input_shape, num_classes, learning_rate=1e-5):\n",
    "    model = Sequential([\n",
    "        LSTM(128, input_shape=input_shape, return_sequences=True),\n",
    "        Dropout(0.5),\n",
    "        LSTM(128, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(num_classes, activation=\"softmax\")\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "# Model setup for high SNR training\n",
    "model_path = \"lstm_rnn_2024.keras\"\n",
    "if os.path.exists(model_path):\n",
    "    print(f\"Loading existing model from {model_path}\")\n",
    "    model = load_model(model_path)\n",
    "else:\n",
    "    print(\"Building new model\")\n",
    "    model = build_model(input_shape=X_train_high.shape[1:], num_classes=len(label_encoder.classes_))\n",
    "\n",
    "# Train the model using only the high SNR (>= -6 dB) data\n",
    "history = model.fit(X_train_high, y_train_high, validation_data=(X_test_high, y_test_high),\n",
    "                    epochs=1, batch_size=64, verbose=1)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2795c-c064-4357-b18a-132f89e57e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# --- Ensure the model is built ---\n",
    "# If the model hasn't been called yet, perform a dummy prediction.\n",
    "dummy_input = np.zeros((1, X_train_high.shape[1], X_train_high.shape[2]))\n",
    "_ = model.predict(dummy_input)\n",
    "\n",
    "# --- 1. Plot Training and Validation Accuracy ---\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- 2. Visualize Activations (\"Feature Maps\") of Selected Layers ---\n",
    "def visualize_feature_maps(model, sample_index=0):\n",
    "    # Select a sample from the high-SNR test set\n",
    "    sample = X_test_high[sample_index:sample_index+1]  # shape: (1, 128, 3)\n",
    "    \n",
    "    # Loop over layers of interest (here, LSTM and Dense layers)\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, (tf.keras.layers.LSTM, tf.keras.layers.Dense)):\n",
    "            try:\n",
    "                # Create an intermediate model to output this layer's activation\n",
    "                intermediate_model = Model(inputs=model.input, outputs=layer.output)\n",
    "                activation = intermediate_model.predict(sample)\n",
    "                \n",
    "                plt.figure(figsize=(10, 4))\n",
    "                if activation.ndim == 3:\n",
    "                    # For LSTM layers with return_sequences=True, visualize as a heatmap\n",
    "                    # (features x time steps)\n",
    "                    sns.heatmap(activation[0].T, cmap='viridis')\n",
    "                    plt.title(f\"Activation from {layer.name} (Heatmap)\")\n",
    "                    plt.xlabel(\"Time steps\")\n",
    "                    plt.ylabel(\"Features\")\n",
    "                elif activation.ndim == 2:\n",
    "                    # For Dense layers (or LSTM with single output), plot as a line plot\n",
    "                    plt.plot(activation[0])\n",
    "                    plt.title(f\"Activation from {layer.name}\")\n",
    "                    plt.xlabel(\"Neuron index\")\n",
    "                    plt.ylabel(\"Activation\")\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            except Exception as e:\n",
    "                print(f\"Could not visualize layer {layer.name}: {e}\")\n",
    "\n",
    "# Visualize activations for a sample from X_test_high\n",
    "visualize_feature_maps(model, sample_index=0)\n",
    "\n",
    "# --- 3. Plot the Confusion Matrix for High SNR Test Data ---\n",
    "# Predict on the high SNR test set\n",
    "y_pred_prob = model.predict(X_test_high)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test_high, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for High SNR (>= -6 dB)\")\n",
    "plt.show()\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(classification_report(y_test_high, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51eed2be-6c82-4c35-b3c7-f0334fcbf16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, LSTM, Dense, Dropout, Add, Concatenate, Lambda\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# -------------------------------\n",
    "# Helper: FFT-Based Filtering Lambda Layer\n",
    "# -------------------------------\n",
    "def fft_filter(x, keep_bins=20):\n",
    "    \"\"\"\n",
    "    Perform FFT on the IQ channels (first two features), zero out all bins \n",
    "    except for the center 'keep_bins' (i.e. the narrow band around DC), then \n",
    "    perform the inverse FFT to get back to the time domain.\n",
    "    \"\"\"\n",
    "    # x shape: (batch, time, features); we use only I and Q.\n",
    "    I = x[..., 0]  # shape: (batch, time)\n",
    "    Q = x[..., 1]  # shape: (batch, time)\n",
    "    # Combine into a complex signal.\n",
    "    complex_signal = tf.complex(I, Q)  # shape: (batch, time)\n",
    "    \n",
    "    # Compute FFT along time axis.\n",
    "    fft_signal = tf.signal.fft(complex_signal)  # shape: (batch, time)\n",
    "    # Shift the zero frequency to the center.\n",
    "    fft_shifted = tf.signal.fftshift(fft_signal, axes=[-1])\n",
    "    \n",
    "    # Create a mask that is 1 for the middle 'keep_bins' indices and 0 elsewhere.\n",
    "    time_dim = tf.shape(fft_shifted)[-1]\n",
    "    center = time_dim // 2\n",
    "    half_keep = keep_bins // 2\n",
    "    lower = center - half_keep\n",
    "    upper = center + half_keep\n",
    "    # Create a mask over the last dimension.\n",
    "    freq_indices = tf.range(time_dim)\n",
    "    mask = tf.cast((freq_indices >= lower) & (freq_indices < upper), fft_shifted.dtype)\n",
    "    mask = tf.reshape(mask, (1, -1))  # shape: (1, time)\n",
    "    # Broadcast the mask to each sample in the batch.\n",
    "    fft_masked = fft_shifted * mask\n",
    "    \n",
    "    # Inverse shift and inverse FFT.\n",
    "    fft_unshifted = tf.signal.ifftshift(fft_masked, axes=[-1])\n",
    "    filtered_complex = tf.signal.ifft(fft_unshifted)\n",
    "    # Take the real part as the filtered time-domain signal.\n",
    "    filtered = tf.math.real(filtered_complex)\n",
    "    # Expand dims to have a channel dimension (so shape becomes (batch, time, 1)).\n",
    "    filtered = tf.expand_dims(filtered, axis=-1)\n",
    "    return filtered\n",
    "\n",
    "# -------------------------------\n",
    "# Model Definition\n",
    "# -------------------------------\n",
    "\n",
    "# Load the original model (frozen left branch)\n",
    "orig_model_path = \"lstm_rnn_2024.keras\"\n",
    "if os.path.exists(orig_model_path):\n",
    "    print(f\"Loading original model from {orig_model_path}\")\n",
    "    orig_model = load_model(orig_model_path)\n",
    "else:\n",
    "    raise FileNotFoundError(f\"{orig_model_path} not found.\")\n",
    "\n",
    "# Use the input from the first layer\n",
    "first_input = orig_model.layers[0].input\n",
    "\n",
    "# Create the left branch by extracting the output from the Dense(128, \"relu\") layer (assumed index=4).\n",
    "left_branch = Model(inputs=first_input, outputs=orig_model.layers[4].output)\n",
    "left_branch.trainable = True  # you mentioned making it trainable for now\n",
    "\n",
    "# Define the overall input (shape: (128, 3) for [I, Q, SNR])\n",
    "input_shape = (128, 3)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Left branch output (processing the raw IQ/SNR input)\n",
    "left_output = left_branch(inputs)\n",
    "\n",
    "# ---------------------------\n",
    "# Right Branch: Apply FFT Filtering, then compute amplitude and phase differences\n",
    "# ---------------------------\n",
    "# Apply FFT filtering to the IQ channels (this should zero out AM-DSB if its energy lies outside the kept bins)\n",
    "filtered_input = Lambda(lambda x: fft_filter(x, keep_bins=20), name=\"fft_filter\")(inputs)\n",
    "# Now compute amplitude and phase differences from the filtered signal.\n",
    "\n",
    "def amplitude_diff_fn(x):\n",
    "    iq = x[..., :1]  # Note: filtered_input has shape (batch, time, 1)\n",
    "    # Since we already combined I and Q in fft_filter, here we just use the filtered result.\n",
    "    # Alternatively, you could compute amplitude from the raw signal if needed.\n",
    "    # For demonstration, we'll treat the filtered output as the \"amplitude\"\n",
    "    amp_diff = x[:, 1:, :] - x[:, :-1, :]\n",
    "    amp_diff = tf.pad(amp_diff, [[0, 0], [1, 0], [0, 0]])\n",
    "    return amp_diff\n",
    "\n",
    "def phase_diff_fn(x):\n",
    "    # Here, since we've applied an FFT filter on IQ, you might choose not to compute phase difference,\n",
    "    # or you could compute it on the raw input. For now, we'll compute it on the raw input.\n",
    "    iq = x[..., :2]  # use the raw I and Q channels\n",
    "    phase = tf.atan2(iq[..., 1], iq[..., 0])\n",
    "    phase_diff = phase[:, 1:] - phase[:, :-1]\n",
    "    phase_diff = tf.pad(phase_diff, [[0, 0], [1, 0]])\n",
    "    phase_diff = tf.expand_dims(phase_diff, axis=-1)\n",
    "    return phase_diff\n",
    "\n",
    "# For this branch, let's use the filtered input to compute amplitude differences,\n",
    "# and use the raw input to compute phase differences.\n",
    "amp_input   = Lambda(amplitude_diff_fn, name=\"amp_diff\")(filtered_input)   # shape: (batch, time, 1)\n",
    "phase_input = Lambda(phase_diff_fn,    name=\"phase_diff\")(inputs)          # shape: (batch, time, 1)\n",
    "\n",
    "# Concatenate amplitude diff and phase diff along the channel axis => shape: (batch, time, 2)\n",
    "combined_input = Concatenate(axis=-1, name=\"combined_amp_phase\")([amp_input, phase_input])\n",
    "\n",
    "# Build a deeper ResLSTM branch with skip connections (using Xavier initialization)\n",
    "r1 = LSTM(128, return_sequences=True, kernel_initializer='glorot_uniform', name=\"res_lstm_1\")(combined_input)\n",
    "r1 = Dropout(0.5, name=\"res_dropout_1\")(r1)\n",
    "\n",
    "r2 = LSTM(128, return_sequences=True, kernel_initializer='glorot_uniform', name=\"res_lstm_2\")(r1)\n",
    "skip1 = Add(name=\"res_skip1\")([r1, r2])\n",
    "skip1 = Dropout(0.5, name=\"res_dropout_2\")(skip1)\n",
    "\n",
    "r3 = LSTM(128, return_sequences=True, kernel_initializer='glorot_uniform', name=\"res_lstm_3\")(skip1)\n",
    "r3 = Dropout(0.5, name=\"res_dropout_3\")(r3)\n",
    "\n",
    "r4 = LSTM(128, return_sequences=True, kernel_initializer='glorot_uniform', name=\"res_lstm_4\")(r3)\n",
    "skip2 = Add(name=\"res_skip2\")([skip1, r4])\n",
    "skip2 = Dropout(0.5, name=\"res_dropout_4\")(skip2)\n",
    "\n",
    "# Final block: produce a single vector from the sequence.\n",
    "r5 = LSTM(128, return_sequences=False, kernel_initializer='glorot_uniform', name=\"res_lstm_5\")(skip2)\n",
    "r5 = Dropout(0.2, name=\"res_dropout_5\")(r5)\n",
    "r5 = Dense(128, activation=\"relu\", kernel_initializer='glorot_uniform', name=\"res_dense\")(r5)\n",
    "r5 = Dropout(0.1, name=\"res_dropout_6\")(r5)\n",
    "\n",
    "# ---------------------------\n",
    "# Combine Branches and Final Classification\n",
    "# ---------------------------\n",
    "combined = Concatenate(name=\"combined_features\")([left_output, r5])\n",
    "num_classes = 11  # Adjust as needed\n",
    "outputs = Dense(num_classes, activation=\"softmax\", name=\"final_output\")(combined)\n",
    "\n",
    "# Build the final Y-network model.\n",
    "y_model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model.\n",
    "optimizer = Adam(learning_rate=1e-5)\n",
    "y_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "# Display the architecture.\n",
    "y_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecc7c28-391e-49c6-844d-68539bac852a",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_dsb_label = label_encoder.transform(['AM-DSB'])[0]  # e.g., 1\n",
    "wb_fm_label  = label_encoder.transform(['WBFM'])[0]    # e.g., 10\n",
    "\n",
    "# Create a dictionary mapping label indices to weights.\n",
    "class_weight = {\n",
    "    am_dsb_label: 4.0,  # Double weight for AM-DSB\n",
    "    wb_fm_label:  4.0   # Double weight for WBFM\n",
    "}\n",
    "\n",
    "# Now train your Y-network model with class_weight:\n",
    "history = y_model.fit(\n",
    "    X_train_high, y_train_high,\n",
    "    validation_data=(X_test_high, y_test_high),\n",
    "    epochs=10, \n",
    "    batch_size=64,\n",
    "    verbose=1,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "# --- Plot Training and Validation Accuracy ---\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_y.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_y.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy (Y-Network)\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- Plot the Confusion Matrix for High SNR Test Data ---\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Predict on the high SNR test set\n",
    "y_pred_prob = y_model.predict(X_test_high)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "cm = confusion_matrix(y_test_high, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=label_encoder.classes_,\n",
    "            yticklabels=label_encoder.classes_)\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix for High SNR (>= -6 dB) Test Data\")\n",
    "plt.show()\n",
    "\n",
    "# Print a detailed classification report\n",
    "print(classification_report(y_test_high, y_pred, target_names=label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed899b53-4246-4f6b-a309-2120bf1b70bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fine tune settings: use a lower learning rate for fine tuning.\n",
    "fine_tune_lr = 1e-7\n",
    "optimizer_finetune = Adam(learning_rate=fine_tune_lr)\n",
    "\n",
    "# Recompile the model so that only the new (trainable) branch and final layers are updated.\n",
    "y_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer_finetune, metrics=[\"accuracy\"])\n",
    "\n",
    "# Fine tune the model on high SNR (>= -6 dB) data\n",
    "history_finetune = y_model.fit(\n",
    "    X_train_high, y_train_high,\n",
    "    validation_data=(X_test_high, y_test_high),\n",
    "    epochs=5,          # Adjust the number of fine-tuning epochs as needed\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Plot fine-tuning training and validation accuracy\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_finetune.history['accuracy'], label='Fine Tune Training Accuracy')\n",
    "plt.plot(history_finetune.history['val_accuracy'], label='Fine Tune Validation Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Fine Tuning: Training and Validation Accuracy (Y-Network)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34177935-f881-4a08-8452-53e648b2fd55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Applying transform: raw_iq ===\n",
      "--> transform=raw_iq, model=mlp, lr=0.0001, wd=0.0001, bs=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/easybuild/software/falcon-sapphirerapids/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1743191602.762889 1269837 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22280 MB memory:  -> device: 0, name: NVIDIA A30, pci bus id: 0000:4a:00.0, compute capability: 8.0\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1743191603.891976 1270112 service.cc:148] XLA service 0x15533801d4a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1743191603.891997 1270112 service.cc:156]   StreamExecutor device (0): NVIDIA A30, Compute Capability 8.0\n",
      "2025-03-28 15:53:23.911922: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1743191604.008709 1270112 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-28 15:53:24.270355: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version 12.5.82. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "I0000 00:00:1743191604.627863 1270112 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> transform=raw_iq, model=mlp, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=raw_iq, model=cnn_1d, lr=0.0001, wd=0.0001, bs=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/easybuild/software/falcon-sapphirerapids/Python/3.11.5-GCCcore-13.2.0/lib/python3.11/site-packages/keras/src/layers/reshaping/reshape.py:39: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> transform=raw_iq, model=cnn_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=raw_iq, model=lstm_1d, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=raw_iq, model=lstm_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "\n",
      "=== Applying transform: fft_mag ===\n",
      "--> transform=fft_mag, model=mlp, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=fft_mag, model=mlp, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=fft_mag, model=cnn_1d, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=fft_mag, model=cnn_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=fft_mag, model=lstm_1d, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=fft_mag, model=lstm_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "\n",
      "=== Applying transform: phase_diff ===\n",
      "--> transform=phase_diff, model=mlp, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=phase_diff, model=mlp, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=phase_diff, model=cnn_1d, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=phase_diff, model=cnn_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=phase_diff, model=lstm_1d, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=phase_diff, model=lstm_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "\n",
      "=== Applying transform: amp_diff ===\n",
      "--> transform=amp_diff, model=mlp, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=amp_diff, model=mlp, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=amp_diff, model=cnn_1d, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=amp_diff, model=cnn_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=amp_diff, model=lstm_1d, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=amp_diff, model=lstm_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "\n",
      "=== Applying transform: square ===\n",
      "--> transform=square, model=mlp, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=square, model=mlp, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=square, model=cnn_1d, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=square, model=cnn_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=square, model=lstm_1d, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=square, model=lstm_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "\n",
      "=== Applying transform: cube ===\n",
      "--> transform=cube, model=mlp, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=cube, model=mlp, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=cube, model=cnn_1d, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=cube, model=cnn_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "--> transform=cube, model=lstm_1d, lr=0.0001, wd=0.0001, bs=32\n",
      "--> transform=cube, model=lstm_1d, lr=1e-05, wd=0.0001, bs=32\n",
      "\n",
      "=== Applying transform: fft_2d ===\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 128 into shape (16,16)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 298\u001b[0m\n\u001b[1;32m    296\u001b[0m X_train_transformed \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(X_train)):\n\u001b[0;32m--> 298\u001b[0m     X_train_transformed\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtransform_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    299\u001b[0m X_train_transformed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(X_train_transformed)\n\u001b[1;32m    301\u001b[0m X_test_transformed \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[3], line 119\u001b[0m, in \u001b[0;36mtransform_fft_2d\u001b[0;34m(iq_sample, n_fft, height, width)\u001b[0m\n\u001b[1;32m    109\u001b[0m log_mag \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(mag \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-6\u001b[39m)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;66;03m# Reshape to 2D, then expand channel\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m# e.g. 16x8 or 16x16 etc. We'll do 16x8 if n_fft=128 -> 128 elements\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# but let's just do 16x8 as an example. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;66;03m# We'll keep it flexible. We'll assume n_fft=256 => 256 magnitude points.\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# Then 16x16 => shape (16,16).\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m reshaped \u001b[38;5;241m=\u001b[39m \u001b[43mlog_mag\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m reshaped \u001b[38;5;241m=\u001b[39m reshaped[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]  \u001b[38;5;66;03m# add channel\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reshaped\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 128 into shape (16,16)"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Flatten, Conv2D, MaxPooling2D, Dropout, Activation, \n",
    "    LSTM, TimeDistributed, BatchNormalization, GlobalAveragePooling2D\n",
    ")\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "###############################################################################\n",
    "# 1. Data: We'll assume you have X_all, y_all, label_encoder (for WBFM vs. AM-DSB).\n",
    "#    We'll do a 2-class scenario with binary labels: 0=AM-DSB, 1=WBFM.\n",
    "###############################################################################\n",
    "# e.g.:\n",
    "# am_dsb_label = label_encoder.transform(['AM-DSB'])[0]\n",
    "# wbfm_label   = label_encoder.transform(['WBFM'])[0]\n",
    "# mask = (y_all == am_dsb_label) | (y_all == wbfm_label)\n",
    "# X_2c = X_all[mask]  # shape: (num_samples, 128, 3) or (num_samples, 128, 2) etc.\n",
    "# y_2c = np.where(y_all[mask] == wbfm_label, 1, 0)\n",
    "# Then train_test_split -> X_train, X_test, y_train, y_test\n",
    "#\n",
    "# We'll assume you already have:\n",
    "#   X_train, X_test, y_train, y_test\n",
    "###############################################################################\n",
    "y_test = y_test_high\n",
    "y_train = y_train_high\n",
    "X_test = X_test_high\n",
    "X_train = X_train_high\n",
    "###############################################################################\n",
    "# 2. Define Feature Transformation Functions\n",
    "###############################################################################\n",
    "# Each function takes raw IQ data (shape: (128, 2) or (128, 3)) and returns\n",
    "# a new feature array (and possibly shape info).\n",
    "\n",
    "def transform_raw_iq(iq_sample):\n",
    "    \"\"\"\n",
    "    Return the raw IQ data (flattened).\n",
    "    E.g. shape -> (128*2,) if ignoring SNR or (128*3,) if you have it.\n",
    "    \"\"\"\n",
    "    # If you have 3 columns [I, Q, SNR], slice if needed. \n",
    "    # For simplicity, assume shape (128,2).\n",
    "    return iq_sample.reshape(-1)  # shape (256,)\n",
    "\n",
    "def transform_fft_mag(iq_sample, n_fft=128):\n",
    "    \"\"\"\n",
    "    Compute FFT magnitude of the IQ signal.\n",
    "    Return flattened log-magnitude, shape ~ (n_fft,).\n",
    "    \"\"\"\n",
    "    # shape (128,2) -> complex\n",
    "    complex_signal = iq_sample[:,0] + 1j*iq_sample[:,1]\n",
    "    fft_result = np.fft.fft(complex_signal, n=n_fft)\n",
    "    mag = np.abs(fft_result)\n",
    "    log_mag = np.log(mag + 1e-6)\n",
    "    return log_mag.astype(np.float32)  # shape (n_fft,)\n",
    "\n",
    "def transform_phase_diff(iq_sample):\n",
    "    \"\"\"\n",
    "    Compute phase difference between successive samples.\n",
    "    Returns shape (128,) for example.\n",
    "    \"\"\"\n",
    "    # shape (128,2)\n",
    "    I = iq_sample[:,0]\n",
    "    Q = iq_sample[:,1]\n",
    "    phase = np.arctan2(Q, I)\n",
    "    diff = np.diff(phase, prepend=phase[0])  # shape (128,)\n",
    "    return diff.astype(np.float32)\n",
    "\n",
    "def transform_amp_diff(iq_sample):\n",
    "    \"\"\"\n",
    "    Compute amplitude difference between successive samples.\n",
    "    \"\"\"\n",
    "    amp = np.sqrt(iq_sample[:,0]**2 + iq_sample[:,1]**2)\n",
    "    diff = np.diff(amp, prepend=amp[0])  # shape (128,)\n",
    "    return diff.astype(np.float32)\n",
    "\n",
    "def transform_square(iq_sample):\n",
    "    \"\"\"\n",
    "    Square each IQ sample: [I^2, Q^2].\n",
    "    Flatten the result.\n",
    "    \"\"\"\n",
    "    squared = iq_sample**2  # shape (128,2)\n",
    "    return squared.reshape(-1).astype(np.float32)\n",
    "\n",
    "def transform_cube(iq_sample):\n",
    "    \"\"\"\n",
    "    Cube each IQ sample: [I^3, Q^3].\n",
    "    Flatten the result.\n",
    "    \"\"\"\n",
    "    cubed = iq_sample**3  # shape (128,2)\n",
    "    return cubed.reshape(-1).astype(np.float32)\n",
    "\n",
    "###############################################################################\n",
    "# 2B. If we want 2D shapes for CNN or ResNet, we can do a small 2D transform:\n",
    "###############################################################################\n",
    "def transform_fft_2d(iq_sample, n_fft=128, height=16, width=16):\n",
    "    \"\"\"\n",
    "    Compute FFT magnitude, reshape to (height, width, 1).\n",
    "    \"\"\"\n",
    "    complex_signal = iq_sample[:,0] + 1j*iq_sample[:,1]\n",
    "    fft_result = np.fft.fft(complex_signal, n=n_fft)\n",
    "    mag = np.abs(fft_result)\n",
    "    log_mag = np.log(mag + 1e-6)\n",
    "    # Reshape to 2D, then expand channel\n",
    "    # e.g. 16x8 or 16x16 etc. We'll do 16x8 if n_fft=128 -> 128 elements\n",
    "    # but let's just do 16x8 as an example. \n",
    "    # We'll do 16x8=128. If we want 16x16, we can zero-pad or something.\n",
    "    # For demonstration, let's do 16x8 => height=16, width=8\n",
    "    # but user said 16x16 => we can zero-pad or just do 256 point FFT.\n",
    "    # We'll keep it flexible. We'll assume n_fft=256 => 256 magnitude points.\n",
    "    # Then 16x16 => shape (16,16).\n",
    "    \n",
    "    reshaped = log_mag.reshape(height, width)\n",
    "    reshaped = reshaped[..., np.newaxis]  # add channel\n",
    "    return reshaped.astype(np.float32)  # shape (16,16,1) if height=16,width=16\n",
    "\n",
    "###############################################################################\n",
    "# 3. Collect Transformations in a Dictionary\n",
    "###############################################################################\n",
    "# Key = name of transform, Value = function that does it (plus info if 1D or 2D)\n",
    "# We'll define which ones produce 1D vs. 2D shapes.\n",
    "\n",
    "transformations = {\n",
    "    'raw_iq':       (transform_raw_iq,  '1d'),\n",
    "    'fft_mag':      (transform_fft_mag, '1d'),\n",
    "    'phase_diff':   (transform_phase_diff, '1d'),\n",
    "    'amp_diff':     (transform_amp_diff,   '1d'),\n",
    "    'square':       (transform_square,  '1d'),\n",
    "    'cube':         (transform_cube,    '1d'),\n",
    "    'fft_2d':       (transform_fft_2d,  '2d'),  # for CNN / ResNet\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 4. Define Some Model-Building Functions\n",
    "###############################################################################\n",
    "def build_mlp(input_dim, lr=1e-4, wd=1e-4):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, activation='relu', kernel_regularizer=l2(wd), input_shape=(input_dim,)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(wd)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(wd)))\n",
    "    model.compile(optimizer=Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_small_cnn_1d(input_dim, lr=1e-4, wd=1e-4):\n",
    "    \"\"\"\n",
    "    A 1D CNN for 1D sequences. \n",
    "    We'll reshape (input_dim,) -> (input_dim,1) for conv1D.\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(tf.keras.layers.Reshape((input_dim, 1), input_shape=(input_dim,)))\n",
    "    model.add(Conv1D(32, kernel_size=3, padding='same', kernel_regularizer=l2(wd), activation='relu'))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(wd)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(wd)))\n",
    "    model.compile(optimizer=Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_small_cnn_2d(input_shape, lr=1e-4, wd=1e-4):\n",
    "    \"\"\"\n",
    "    A small 2D CNN for shape e.g. (16,16,1).\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=l2(wd), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=l2(wd), activation='relu'))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(wd)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(wd)))\n",
    "    model.compile(optimizer=Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_resnet20_2d(input_shape, lr=1e-4, wd=1e-4):\n",
    "    \"\"\"\n",
    "    A ResNet20 for 2D inputs (like your existing code).\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, Add, AveragePooling2D, Flatten\n",
    "    from tensorflow.keras.models import Model\n",
    "    \n",
    "    def resnet_layer(inputs, num_filters=16, kernel_size=3, strides=1,\n",
    "                     activation='relu', batch_normalization=True, conv_first=True):\n",
    "        conv = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same',\n",
    "                      kernel_initializer='he_normal', kernel_regularizer=l2(wd))\n",
    "        x = inputs\n",
    "        if conv_first:\n",
    "            x = conv(x)\n",
    "            if batch_normalization:\n",
    "                x = BatchNormalization()(x)\n",
    "            if activation is not None:\n",
    "                x = Activation(activation)(x)\n",
    "        else:\n",
    "            if batch_normalization:\n",
    "                x = BatchNormalization()(x)\n",
    "            if activation is not None:\n",
    "                x = Activation(activation)(x)\n",
    "            x = conv(x)\n",
    "        return x\n",
    "\n",
    "    def resnet_block(inputs, num_filters, downsample=False):\n",
    "        strides = 2 if downsample else 1\n",
    "        x = resnet_layer(inputs, num_filters=num_filters, strides=strides)\n",
    "        x = resnet_layer(x, num_filters=num_filters, activation=None)\n",
    "        # shortcut\n",
    "        if downsample or inputs.shape[-1] != num_filters:\n",
    "            shortcut = Conv2D(num_filters, kernel_size=1, strides=strides, padding='same',\n",
    "                              kernel_initializer='he_normal', kernel_regularizer=l2(wd))(inputs)\n",
    "            shortcut = BatchNormalization()(shortcut)\n",
    "        else:\n",
    "            shortcut = inputs\n",
    "        x = Add()([x, shortcut])\n",
    "        x = Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs, num_filters=16, conv_first=True)\n",
    "    \n",
    "    num_filters = 16\n",
    "    for stack in range(3):\n",
    "        for block in range(3):\n",
    "            downsample = True if (stack > 0 and block == 0) else False\n",
    "            x = resnet_block(x, num_filters, downsample=downsample)\n",
    "        num_filters *= 2\n",
    "\n",
    "    x = AveragePooling2D(pool_size=2)(x)  # if input is small, adjust\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(1, activation='sigmoid', kernel_regularizer=l2(wd))(x)\n",
    "    \n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def build_lstm_1d(input_dim, lr=1e-4, wd=1e-4):\n",
    "    \"\"\"\n",
    "    A simple LSTM model for 1D sequences. We'll reshape (input_dim,) -> (input_dim,1).\n",
    "    \"\"\"\n",
    "    from tensorflow.keras.layers import Reshape\n",
    "    model = Sequential()\n",
    "    model.add(Reshape((input_dim,1), input_shape=(input_dim,)))\n",
    "    model.add(LSTM(64, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(wd)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(wd)))\n",
    "    model.compile(optimizer=Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "###############################################################################\n",
    "# 5. Create a Dictionary of Models (by name) that Expect 1D or 2D Input\n",
    "###############################################################################\n",
    "model_registry_1d = {\n",
    "    'mlp':        build_mlp,\n",
    "    'cnn_1d':     build_small_cnn_1d,\n",
    "    'lstm_1d':    build_lstm_1d\n",
    "}\n",
    "model_registry_2d = {\n",
    "    'cnn_2d':     build_small_cnn_2d,\n",
    "    'resnet20_2d': build_resnet20_2d\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 6. Grid Search\n",
    "###############################################################################\n",
    "transform_choices = ['raw_iq', 'fft_mag', 'phase_diff', 'amp_diff', 'square', 'cube', 'fft_2d']\n",
    "model_choices_1d = ['mlp', 'cnn_1d', 'lstm_1d']\n",
    "model_choices_2d = ['cnn_2d', 'resnet20_2d']\n",
    "learning_rates = [1e-4, 1e-5]\n",
    "weight_decays = [1e-4]\n",
    "batch_sizes = [32]\n",
    "\n",
    "results = []\n",
    "early_stopping = EarlyStopping(patience=3, restore_best_weights=True, monitor='val_loss')\n",
    "\n",
    "for transform_name in transform_choices:\n",
    "    transform_func, transform_type = transformations[transform_name]\n",
    "    \n",
    "    # Determine which model registry to use based on transform_type\n",
    "    if transform_type == '1d':\n",
    "        possible_models = model_choices_1d\n",
    "    else:\n",
    "        possible_models = model_choices_2d\n",
    "    \n",
    "    # Pre-transform the data once so we don't redo for every hyperparam\n",
    "    print(f\"\\n=== Applying transform: {transform_name} ===\")\n",
    "    X_train_transformed = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_train_transformed.append(transform_func(X_train[i]))\n",
    "    X_train_transformed = np.array(X_train_transformed)\n",
    "    \n",
    "    X_test_transformed = []\n",
    "    for i in range(len(X_test)):\n",
    "        X_test_transformed.append(transform_func(X_test[i]))\n",
    "    X_test_transformed = np.array(X_test_transformed)\n",
    "    \n",
    "    # If transform_type='2d', figure out input shape for the model\n",
    "    # e.g. if it's (16,16,1) or something\n",
    "    if transform_type == '2d':\n",
    "        shape_2d = X_train_transformed[0].shape  # e.g. (16,16,1)\n",
    "    else:\n",
    "        shape_1d = X_train_transformed[0].shape  # e.g. (256,) or (128,)\n",
    "\n",
    "    for model_name in possible_models:\n",
    "        for lr in learning_rates:\n",
    "            for wd in weight_decays:\n",
    "                for bs in batch_sizes:\n",
    "                    print(f\"--> transform={transform_name}, model={model_name}, lr={lr}, wd={wd}, bs={bs}\")\n",
    "                    \n",
    "                    # Build the model\n",
    "                    if transform_type == '1d':\n",
    "                        input_dim = shape_1d[0] if len(shape_1d) == 1 else np.prod(shape_1d)\n",
    "                        # In case shape_1d is (128,2), flatten\n",
    "                        # But we've typically already flattened in transform...\n",
    "                        # We'll assume it's 1D now. \n",
    "                        model_fn = model_registry_1d[model_name]\n",
    "                        model = model_fn(input_dim=input_dim, lr=lr, wd=wd)\n",
    "                    else:\n",
    "                        # 2D\n",
    "                        model_fn = model_registry_2d[model_name]\n",
    "                        model = model_fn(input_shape=shape_2d, lr=lr, wd=wd)\n",
    "                    \n",
    "                    # Train\n",
    "                    history = model.fit(\n",
    "                        X_train_transformed, y_train,\n",
    "                        validation_data=(X_test_transformed, y_test),\n",
    "                        epochs=10,\n",
    "                        batch_size=bs,\n",
    "                        callbacks=[early_stopping],\n",
    "                        verbose=0\n",
    "                    )\n",
    "                    \n",
    "                    # Evaluate\n",
    "                    val_loss, val_acc = model.evaluate(X_test_transformed, y_test, verbose=0)\n",
    "                    y_pred_prob = model.predict(X_test_transformed, verbose=0)\n",
    "                    y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "                    \n",
    "                    results.append({\n",
    "                        'transform': transform_name,\n",
    "                        'model': model_name,\n",
    "                        'lr': lr,\n",
    "                        'weight_decay': wd,\n",
    "                        'batch_size': bs,\n",
    "                        'val_acc': val_acc,\n",
    "                        'val_loss': val_loss\n",
    "                    })\n",
    "\n",
    "###############################################################################\n",
    "# 7. Print a Table of Accuracies\n",
    "###############################################################################\n",
    "# Sort results by val_acc descending\n",
    "results_sorted = sorted(results, key=lambda x: x['val_acc'], reverse=True)\n",
    "\n",
    "print(\"\\n================ Grid Search Results ================\")\n",
    "print(f\"{'Transform':<12} {'Model':<10} {'LR':<8} {'WD':<8} {'BS':<5} {'Val_Acc':<8} {'Val_Loss'}\")\n",
    "print(\"-\"*70)\n",
    "for r in results_sorted:\n",
    "    print(f\"{r['transform']:<12} {r['model']:<10} {r['lr']:<8.0e} {r['weight_decay']:<8.0e} {r['batch_size']:<5} {r['val_acc']:<8.3f} {r['val_loss']:.3f}\")\n",
    "\n",
    "# You could also print only top 10, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805666c-7f3c-452d-bf63-b4dbecb7913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "############################################\n",
    "# 1. Prepare the Binary Dataset (WBFM vs. AM-DSB)\n",
    "############################################\n",
    "# Assume X_all, y_all, and label_encoder are already defined.\n",
    "# For example, label_encoder.classes_ might be:\n",
    "# ['8PSK','AM-DSB','AM-SSB','BPSK','CPFSK','GFSK','PAM4','QAM16','QAM64','QPSK','WBFM']\n",
    "am_dsb_label = label_encoder.transform(['AM-DSB'])[0]\n",
    "wbfm_label   = label_encoder.transform(['WBFM'])[0]\n",
    "\n",
    "# Filter to only these two classes.\n",
    "mask = (y_all == am_dsb_label) | (y_all == wbfm_label)\n",
    "X_2c = X_all[mask]\n",
    "y_2c = y_all[mask]\n",
    "# Convert labels to binary: 0 for AM-DSB, 1 for WBFM.\n",
    "y_2c_binary = np.where(y_2c == wbfm_label, 1, 0)\n",
    "\n",
    "# Split into train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_2c, y_2c_binary, test_size=0.2, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# For FFT processing we use only the IQ channels (first 2 columns).\n",
    "X_train_iq = X_train[..., :2]  # shape: (num_samples, 128, 2)\n",
    "X_test_iq  = X_test[..., :2]\n",
    "\n",
    "############################################\n",
    "# 2. Group 20 Successive Signals\n",
    "############################################\n",
    "group_size = 20\n",
    "\n",
    "def group_signals(X, y, group_size):\n",
    "    \"\"\"\n",
    "    Group every group_size signals into one sample.\n",
    "    Returns new X with shape (num_groups, group_size, 128, channels)\n",
    "    and new y with shape (num_groups,) (using the label of the first signal).\n",
    "    \"\"\"\n",
    "    n_groups = X.shape[0] // group_size\n",
    "    X_grouped = X[:n_groups*group_size].reshape(n_groups, group_size, X.shape[1], X.shape[2])\n",
    "    y_grouped = y[:n_groups*group_size].reshape(n_groups, group_size)[:,0]\n",
    "    return X_grouped, y_grouped\n",
    "\n",
    "X_train_grouped, y_train_grouped = group_signals(X_train_iq, y_train, group_size)\n",
    "X_test_grouped, y_test_grouped   = group_signals(X_test_iq, y_test, group_size)\n",
    "\n",
    "############################################\n",
    "# 3. Compute FFT on Cubed IQ Data\n",
    "############################################\n",
    "def compute_fft_for_signal_cubed(signal, n_fft=128):\n",
    "    \"\"\"\n",
    "    1) Cube the IQ data: [I^3, Q^3]\n",
    "    2) Form a complex signal\n",
    "    3) Compute FFT (length n_fft)\n",
    "    4) Return log-magnitude as 1D array (n_fft,)\n",
    "    \"\"\"\n",
    "    # shape: (128,2)\n",
    "    cubed = signal**3\n",
    "    # Create a complex signal from the cubed IQ\n",
    "    complex_signal = cubed[:,0] + 1j * cubed[:,1]\n",
    "    fft_result = np.fft.fft(complex_signal, n=n_fft)\n",
    "    mag = np.abs(fft_result)\n",
    "    log_mag = np.log(mag + 1e-6)\n",
    "    return log_mag  # shape: (n_fft,)\n",
    "\n",
    "def transform_group_cubed(group, n_fft=128):\n",
    "    \"\"\"\n",
    "    For a group of 20 signals (shape: (20, 128, 2)), compute cubed-FFT log-magnitude \n",
    "    for each signal and vertically stack them.\n",
    "    Returns an array of shape (20, n_fft).\n",
    "    \"\"\"\n",
    "    fft_list = []\n",
    "    for signal in group:\n",
    "        fft_list.append(compute_fft_for_signal_cubed(signal, n_fft))\n",
    "    stacked = np.stack(fft_list, axis=0)  # shape: (20, n_fft)\n",
    "    return stacked\n",
    "\n",
    "def transform_dataset_cubed(X_grouped, n_fft=128):\n",
    "    \"\"\"\n",
    "    Apply transform_group_cubed to each group, add a channel dim => shape: (20, n_fft, 1)\n",
    "    \"\"\"\n",
    "    transformed = []\n",
    "    for group in X_grouped:\n",
    "        fft_image = transform_group_cubed(group, n_fft=n_fft)\n",
    "        fft_image = np.expand_dims(fft_image, axis=-1)  # (20, n_fft, 1)\n",
    "        transformed.append(fft_image)\n",
    "    return np.array(transformed, dtype=np.float32)\n",
    "\n",
    "print(\"Transforming training groups (cubed IQ) ...\")\n",
    "X_train_trans = transform_dataset_cubed(X_train_grouped, n_fft=128)\n",
    "print(\"Transforming test groups (cubed IQ) ...\")\n",
    "X_test_trans  = transform_dataset_cubed(X_test_grouped, n_fft=128)\n",
    "\n",
    "print(\"Transformed training shape:\", X_train_trans.shape)  # e.g. (num_groups, 20, 128, 1)\n",
    "print(\"Transformed test shape:\", X_test_trans.shape)\n",
    "\n",
    "############################################\n",
    "# 4. Build a CNN Model for Group FFT Images\n",
    "############################################\n",
    "def build_group_cnn(input_shape=(20,128,1), lr=1e-4):\n",
    "    model = Sequential([\n",
    "        Conv2D(32, kernel_size=(3,3), activation='relu', padding='same', input_shape=input_shape),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'),\n",
    "        MaxPooling2D(pool_size=(2,2)),\n",
    "        Dropout(0.3),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "group_cnn_cubed = build_group_cnn(input_shape=(20,128,1), lr=1e-4)\n",
    "group_cnn_cubed.summary()\n",
    "\n",
    "############################################\n",
    "# 5. Train the CNN Model\n",
    "############################################\n",
    "history_cubed = group_cnn_cubed.fit(\n",
    "    X_train_trans, y_train_grouped,\n",
    "    validation_data=(X_test_trans, y_test_grouped),\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "############################################\n",
    "# 6. Evaluate and Plot a Confusion Matrix\n",
    "############################################\n",
    "y_pred_prob = group_cnn_cubed.predict(X_test_trans)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
    "\n",
    "cm = confusion_matrix(y_test_grouped, y_pred)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['AM-DSB', 'WBFM'],\n",
    "            yticklabels=['AM-DSB', 'WBFM'])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (Grouped FFT CNN - Cubed IQ)\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test_grouped, y_pred, target_names=['AM-DSB', 'WBFM']))\n",
    "\n",
    "############################################\n",
    "# 7. Summarize the Result in a Table\n",
    "############################################\n",
    "val_loss, val_acc = group_cnn_cubed.evaluate(X_test_trans, y_test_grouped, verbose=0)\n",
    "results_table = pd.DataFrame({\n",
    "    'Model': ['Group_CNN_Cubed'],\n",
    "    'Group Size': [20],\n",
    "    'FFT Length': [128],\n",
    "    'Val_Accuracy': [val_acc],\n",
    "    'Val_Loss': [val_loss]\n",
    "})\n",
    "\n",
    "print(\"\\n===== Summary of Results (Cubed IQ) =====\")\n",
    "print(results_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286aa1af-1cc0-44e7-9604-e2c1fa17f0a3",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
