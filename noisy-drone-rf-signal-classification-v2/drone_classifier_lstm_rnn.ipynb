{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa778862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Imports\n",
    "# ------------------------------------------------------------\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import scipy.signal as sg\n",
    "import kagglehub\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Kaggle Download\n",
    "# ------------------------------------------------------------\n",
    "path = kagglehub.dataset_download(\"hyelinnam/noisy-drone-rf-signal-classification-v2\")\n",
    "print(\"Dataset path:\", path)\n",
    "\n",
    "# Inspect folder\n",
    "print(os.listdir(path))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load IQ Data\n",
    "# Assumes .npy files: shape = (N, 2) for I and Q\n",
    "# ------------------------------------------------------------\n",
    "iq_files = glob.glob(os.path.join(path, \"**\", \"*.npy\"), recursive=True)\n",
    "print(\"Found IQ files:\", len(iq_files))\n",
    "\n",
    "signals = []\n",
    "labels = []\n",
    "\n",
    "for f in iq_files:\n",
    "    arr = np.load(f)\n",
    "    signals.append(arr)\n",
    "\n",
    "    # Label determined from filename prefix\n",
    "    lbl = os.path.basename(f).split(\"_\")[0]\n",
    "    labels.append(lbl)\n",
    "\n",
    "signals = np.array(signals)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(\"Signals shape:\", signals.shape)\n",
    "print(\"Unique labels:\", np.unique(labels))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Encode labels\n",
    "# ------------------------------------------------------------\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(labels)\n",
    "class_names = list(enc.classes_)\n",
    "print(\"Encoded classes:\", class_names)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# EDA: Waveform, Spectrum, Waterfall\n",
    "# ------------------------------------------------------------\n",
    "# Pick first example\n",
    "idx = 0\n",
    "iq = signals[idx]\n",
    "I = iq[:,0]\n",
    "Q = iq[:,1]\n",
    "complex_sig = I + 1j*Q\n",
    "\n",
    "# Set sampling rate if known; otherwise approximate\n",
    "fs = 1e6  # modify if dataset metadata states otherwise\n",
    "\n",
    "fig, ax = plt.subplots(3,1, figsize=(12,12))\n",
    "\n",
    "# 1. Time-domain I/Q\n",
    "ax[0].plot(I, label=\"I\")\n",
    "ax[0].plot(Q, label=\"Q\")\n",
    "ax[0].set_title(\"Time Domain I/Q\")\n",
    "ax[0].legend()\n",
    "\n",
    "# 2. Magnitude Spectrum\n",
    "f, Pxx = sg.welch(complex_sig, fs=fs, nperseg=1024)\n",
    "ax[1].semilogy(f, Pxx)\n",
    "ax[1].set_title(\"Magnitude Spectrum\")\n",
    "\n",
    "# 3. Waterfall / Spectrogram\n",
    "f_s, t_s, Sxx = sg.spectrogram(complex_sig, fs=fs, nperseg=256, noverlap=128)\n",
    "pcm = ax[2].pcolormesh(t_s, f_s, 10*np.log10(Sxx + 1e-12), shading=\"auto\")\n",
    "ax[2].set_title(\"Waterfall Spectrogram\")\n",
    "ax[2].set_ylabel(\"Frequency (Hz)\")\n",
    "ax[2].set_xlabel(\"Time (sec)\")\n",
    "plt.colorbar(pcm, ax=ax[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b923af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------\n",
    "# Preprocess for LSTM\n",
    "# Standardize I/Q jointly per-feature.\n",
    "# ------------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "X = signals.astype(np.float32)\n",
    "\n",
    "# Standardize across entire dataset\n",
    "scaler = StandardScaler()\n",
    "X_flat = X.reshape(-1, 2)\n",
    "X_flat = scaler.fit_transform(X_flat)\n",
    "X = X_flat.reshape(X.shape)\n",
    "\n",
    "print(\"Final X shape:\", X.shape)\n",
    "print(\"Final y shape:\", y.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Train / Val / Test split\n",
    "# ------------------------------------------------------------\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape)\n",
    "print(\"Val:\", X_val.shape)\n",
    "print(\"Test:\", X_test.shape)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# LSTM / BiLSTM Model (same pattern as ViC notebook)\n",
    "# ------------------------------------------------------------\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "\n",
    "num_classes = len(class_names)\n",
    "timesteps = X_train.shape[1]\n",
    "features = X_train.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(timesteps, features)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Training\n",
    "# ------------------------------------------------------------\n",
    "early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[early],\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Plot training curves\n",
    "# ------------------------------------------------------------\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Evaluate on test set\n",
    "# ------------------------------------------------------------\n",
    "test_probs = model.predict(X_test, batch_size=64)\n",
    "test_pred = np.argmax(test_probs, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, test_pred)\n",
    "print(\"Test accuracy:\", acc)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Confusion Matrix\n",
    "# ------------------------------------------------------------\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
    "disp.plot(ax=ax, cmap=\"magma\", xticks_rotation=45)\n",
    "plt.title(\"LSTM Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
