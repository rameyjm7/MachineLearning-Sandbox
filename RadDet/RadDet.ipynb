{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce77b51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RadDet ICASSP 2025 Radar Spectrum Detection Dataset\n",
    "# Cell 1: Download, extract, visualize, EDA\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import tarfile\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Step 1: Download Kaggle dataset\n",
    "# ------------------------------------------------------------\n",
    "print(\"Downloading RadDet dataset from Kaggle...\")\n",
    "dataset_path = kagglehub.dataset_download(\"abcxyzi/raddet-icassp-2025\")\n",
    "print(\"Dataset downloaded to:\", dataset_path)\n",
    "\n",
    "# The downloaded directory will contain ~21 multi-part tar files.\n",
    "# We reassemble each dataset according to its naming pattern.\n",
    "\n",
    "parts = sorted(glob.glob(os.path.join(dataset_path, \"*.part-*\")))\n",
    "print(\"Found multipart archives:\", len(parts))\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Step 2: Auto-recombine all multi-part tar files\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def recombine_tar(prefix):\n",
    "    \"\"\"Recombine all .part-* for a given prefix.tar.part-*\"\"\"\n",
    "    part_files = sorted(glob.glob(os.path.join(dataset_path, prefix + \".part-*\")))\n",
    "    if not part_files:\n",
    "        return None\n",
    "\n",
    "    combined = os.path.join(dataset_path, prefix + \".tar\")\n",
    "    if os.path.exists(combined):\n",
    "        return combined\n",
    "\n",
    "    print(f\"Recombining: {prefix}\")\n",
    "    with open(combined, \"wb\") as outfile:\n",
    "        for p in part_files:\n",
    "            with open(p, \"rb\") as infile:\n",
    "                outfile.write(infile.read())\n",
    "    return combined\n",
    "\n",
    "# Detect all unique prefixes\n",
    "unique_prefixes = sorted(\n",
    "    set(os.path.basename(p).split(\".part-\")[0] for p in parts)\n",
    ")\n",
    "\n",
    "combined_archives = []\n",
    "for prefix in unique_prefixes:\n",
    "    t = recombine_tar(prefix)\n",
    "    if t is not None:\n",
    "        combined_archives.append(t)\n",
    "\n",
    "print(\"Combined archives:\", combined_archives)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Step 3: Extract each tar (will create images/, labels/, etc.)\n",
    "# ------------------------------------------------------------\n",
    "extract_dir = os.path.join(dataset_path, \"extracted\")\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "for t in combined_archives:\n",
    "    print(\"Extracting:\", t)\n",
    "    with tarfile.open(t, \"r\") as tar:\n",
    "        tar.extractall(extract_dir)\n",
    "\n",
    "print(\"Extraction complete.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Step 4: EDA â€“ Inspect sample images and draw bbox overlays\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Locate PNGs and YOLO label files\n",
    "pngs = sorted(glob.glob(os.path.join(extract_dir, \"**\", \"*.png\"), recursive=True))\n",
    "txts = [p.replace(\".png\", \".txt\") for p in pngs]\n",
    "\n",
    "print(\"Sample count:\", len(pngs))\n",
    "\n",
    "def load_yolo_bboxes(label_file):\n",
    "    \"\"\"Load YOLO (class cx cy w h) format.\"\"\"\n",
    "    if not os.path.exists(label_file):\n",
    "        return []\n",
    "    boxes = []\n",
    "    with open(label_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            vals = line.strip().split()\n",
    "            cls = int(vals[0])\n",
    "            cx, cy, w, h = map(float, vals[1:])\n",
    "            boxes.append((cls, cx, cy, w, h))\n",
    "    return boxes\n",
    "\n",
    "def draw_boxes(im, bboxes, color=(255,0,0)):\n",
    "    \"\"\"Draw YOLO-format boxes on image.\"\"\"\n",
    "    h, w = im.shape[:2]\n",
    "    overlay = im.copy()\n",
    "    for cls, cx, cy, bw, bh in bboxes:\n",
    "        x1 = int((cx - bw/2) * w)\n",
    "        y1 = int((cy - bh/2) * h)\n",
    "        x2 = int((cx + bw/2) * w)\n",
    "        y2 = int((cy + bh/2) * h)\n",
    "        cv2.rectangle(overlay, (x1,y1), (x2,y2), color, 1)\n",
    "    return overlay\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# EDA Visualizations\n",
    "# ------------------------------------------------------------\n",
    "n_show = 4\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(n_show):\n",
    "    img_path = pngs[i]\n",
    "    lbl_path = txts[i]\n",
    "    im = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "    bboxes = load_yolo_bboxes(lbl_path)\n",
    "    im2 = draw_boxes(im, bboxes)\n",
    "\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.imshow(im2, cmap=\"gray\")\n",
    "    plt.title(f\"Frame {i}, boxes={len(bboxes)}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Step 5: Waterfall view\n",
    "# Convert spectrogram into stacked frequency slices for visualization\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def waterfall_view(im, slices=64):\n",
    "    h, w = im.shape[:2]\n",
    "    slice_h = h // slices\n",
    "    wf = [im[i*slice_h:(i+1)*slice_h, :].mean(axis=0) for i in range(slices)]\n",
    "    return np.array(wf)\n",
    "\n",
    "sample = np.array(Image.open(pngs[0]).convert(\"L\"))\n",
    "wf = waterfall_view(sample, slices=128)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.imshow(wf, aspect=\"auto\", cmap=\"inferno\")\n",
    "plt.title(\"Waterfall\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Time slice index\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110d06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# RadDet Radar Detection Baseline Training\n",
    "# Cell 2: Model, Training, Evaluation\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# You can train YOLO directly with the provided data.yaml\n",
    "# Choose any of these (256 recommended as baseline speed/accuracy tradeoff)\n",
    "\n",
    "data_yaml = os.path.join(dataset_path, \"extracted\", \"data.yaml\")\n",
    "print(\"Using config:\", data_yaml)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Step 1: Load YOLO model (YOLOv8n as baseline)\n",
    "# ------------------------------------------------------------\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Step 2: Train\n",
    "# ------------------------------------------------------------\n",
    "results = model.train(\n",
    "    data=data_yaml,\n",
    "    imgsz=256,\n",
    "    epochs=30,\n",
    "    batch=16,\n",
    "    lr0=0.001,\n",
    "    device=0,\n",
    "    project=os.path.join(dataset_path, \"runs\"),\n",
    "    name=\"raddet_yolov8n_baseline\",\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Step 3: Evaluate on test set\n",
    "# ------------------------------------------------------------\n",
    "metrics = model.val()\n",
    "print(\"Validation metrics:\", metrics)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Step 4: Export as TensorFlow SavedModel or Keras\n",
    "# ------------------------------------------------------------\n",
    "export_dir = os.path.join(dataset_path, \"yolo_export\")\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "\n",
    "model.export(format=\"saved_model\", out=export_dir)\n",
    "print(\"Export saved to:\", export_dir)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
